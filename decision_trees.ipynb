{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision_trees.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "nLEUmjsnvkRy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from copy import copy\n",
        "import graphviz\n",
        "from sklearn import tree\n",
        "from google.colab import drive\n",
        "test_labels = np.load ('/content/drive/MyDrive/hw3_material (1)/dt/test_labels.npy')\n",
        "test_set = np.load ('/content/drive/MyDrive/hw3_material (1)/dt/test_set.npy')\n",
        "train_labels = np.load ('/content/drive/MyDrive/hw3_material (1)/dt/train_labels.npy')\n",
        "train_set = np.load ('/content/drive/MyDrive/hw3_material (1)/dt/train_set.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(bucket):\n",
        "    \"\"\"\n",
        "    Calculates the entropy.\n",
        "    :param bucket: A list of size num_classes. bucket[i] is the number of\n",
        "    examples that belong to class i.\n",
        "    :return: A float. Calculated entropy.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Entropy(S) = - (p1 * log(p1)) - (p2 * log(p2)) \n",
        "    p1 is the proportion of examples in class 1\n",
        "    p2 is the proportion of examples in class 2\n",
        "    p2 = 1 - p1 is the proportion of examples in class 2\n",
        "    \"\"\"\n",
        "\n",
        "    total_no_instances = sum(bucket)\n",
        "\n",
        "    if total_no_instances == 0:\n",
        "        return 0\n",
        "\n",
        "    calculated_entropy = 0\n",
        "\n",
        "    # loop through the different classes and calculate their proportions\n",
        "    for i in range (len(bucket)):\n",
        "        p = (bucket[i] / total_no_instances)\n",
        "\n",
        "        if p != 0:\n",
        "            calculated_entropy += (-p * math.log2(p))\n",
        "\n",
        "    return calculated_entropy"
      ],
      "metadata": {
        "id": "oIDP7cuXwx_N"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def info_gain(parent_bucket, left_bucket, right_bucket):\n",
        "    \"\"\"\n",
        "    Calculates the information gain. A bucket is a list of size num_classes.\n",
        "    bucket[i] is the number of examples that belong to class i.\n",
        "    :param parent_bucket: Bucket belonging to the parent node. It contains the\n",
        "    number of examples that belong to each class before the split.\n",
        "    :param left_bucket: Bucket belonging to the left child after the split.\n",
        "    :param right_bucket: Bucket belonging to the right child after the split.\n",
        "    :return: A float. Calculated information gain.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "     When an attribute A splits the set S into subsets Si\n",
        "     we compute the average entropy\n",
        "     and compare the sum to the entropy of the original set S\n",
        "    \"\"\"\n",
        "\n",
        "    entropy_original_set = entropy(parent_bucket)\n",
        "\n",
        "    information_gain = entropy_original_set\n",
        "\n",
        "    information_gain -= ((sum(left_bucket) / sum(parent_bucket)) * entropy(left_bucket))\n",
        "    information_gain -= ((sum(right_bucket) / sum(parent_bucket)) * entropy(right_bucket))\n",
        "\n",
        "    return information_gain\n"
      ],
      "metadata": {
        "id": "dYpCNgDIxF9x"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(bucket):\n",
        "    \"\"\"\n",
        "    Calculates the gini index.\n",
        "    :param bucket: A list of size num_classes. bucket[i] is the number of\n",
        "    examples that belong to class i.\n",
        "    :return: A float. Calculated gini index.\n",
        "    \"\"\"\n",
        "\n",
        "    total_no_instances = sum(bucket)\n",
        "    if total_no_instances == 0:\n",
        "        return 1\n",
        "\n",
        "    gini_index = 1\n",
        "\n",
        "    for i in range(len(bucket)):\n",
        "        p = (bucket[i] / total_no_instances)\n",
        "        gini_index -= (p*p)\n",
        "\n",
        "    return gini_index"
      ],
      "metadata": {
        "id": "rwLwjzTixMLB"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_gini_index(left_bucket, right_bucket):\n",
        "    \"\"\"\n",
        "    Calculates the average gini index. A bucket is a list of size num_classes.\n",
        "    bucket[i] is the number of examples that belong to class i.\n",
        "    :param left_bucket: Bucket belonging to the left child after the split.\n",
        "    :param right_bucket: Bucket belonging to the right child after the split.\n",
        "    :return: A float. Calculated average gini index.\n",
        "    \"\"\"\n",
        "    total_no_instances = sum(left_bucket) + sum(right_bucket)\n",
        "\n",
        "    avg_gini = (sum(left_bucket) / total_no_instances) * gini(left_bucket)\n",
        "    avg_gini += (sum(right_bucket) / total_no_instances) * gini(right_bucket)\n",
        "\n",
        "    return avg_gini"
      ],
      "metadata": {
        "id": "XfqmbWvvxPAi"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selectionSort(data, labels, attr_index):\n",
        "    for i in range(data.shape[0]):\n",
        "        minimum = 10000\n",
        "        minimum_index = i\n",
        "\n",
        "        for j in range(i, data.shape[0]):\n",
        "            if data[j][attr_index] < minimum:\n",
        "                minimum = data[j][attr_index]\n",
        "                minimum_index = j\n",
        "\n",
        "\n",
        "        # sort the data\n",
        "        temp = copy(data[i])\n",
        "        data[i] = copy(data[minimum_index])\n",
        "        data[minimum_index] = temp\n",
        "\n",
        "        # sort the label\n",
        "        temp = copy(labels[i])\n",
        "        labels[i] = copy(labels[minimum_index])\n",
        "        labels[minimum_index] = temp\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "la3PQgRj_6J0"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_split_values(data, labels, num_classes, attr_index, heuristic_name):\n",
        "    \"\"\"\n",
        "    For every possible values to split the data for the attribute indexed by\n",
        "    attribute_index, it divides the data into buckets and calculates the values\n",
        "    returned by the heuristic function named heuristic_name. The split values\n",
        "    should be the average of the closest 2 values. For example, if the data has\n",
        "    2.1 and 2.2 in it consecutively for the values of attribute index by attr_index,\n",
        "    then one of the split values should be 2.15.\n",
        "    :param data: An (N, M) shaped numpy array. N is the number of examples in the\n",
        "    current node. M is the dimensionality of the data. It contains the values for\n",
        "    every attribute for every example.\n",
        "    :param labels: An (N, ) shaped numpy array. It contains the class values in\n",
        "    it. For every value, 0 <= value < num_classes.\n",
        "    :param num_classes: An integer. The number of classes in the dataset.\n",
        "    :param attr_index: An integer. The index of the attribute that is going to\n",
        "    be used for the splitting operation. This integer indexs the second dimension\n",
        "    of the data numpy array.\n",
        "    :param heuristic_name: The name of the heuristic function. It should either be\n",
        "    'info_gain' of 'avg_gini_index' for this homework.\n",
        "    :return: An (L, 2) shaped numpy array. L is the number of split values. The\n",
        "    first column is the split values and the second column contains the calculated\n",
        "    heuristic values for their splits.\n",
        "    \"\"\"\n",
        "\n",
        "    data, labels = selectionSort(data, labels, attr_index)\n",
        "\n",
        "    split_value_of_heuristic = np.zeros((data.shape[0] - 1, 2))\n",
        "    left_bucket = np.zeros(max(labels) + 1)\n",
        "    right_bucket = np.zeros(max(labels) + 1)\n",
        "    if heuristic_name == 'avg_gini_index':\n",
        "        for i in range(data.shape[0] - 1):\n",
        "            split_value = (data[i][attr_index] + data[i+1][attr_index]) / 2\n",
        "            for j in range(data.shape[0]):\n",
        "                if data[j][attr_index] <= split_value:\n",
        "                    left_bucket[labels[j]] = left_bucket[labels[j]] + 1\n",
        "                else: \n",
        "                    right_bucket[labels[j]] = right_bucket[labels[j]] + 1\n",
        "               \n",
        "            split_value_of_heuristic[i][0] = split_value\n",
        "            split_value_of_heuristic[i][1] = avg_gini_index(left_bucket.tolist(), right_bucket.tolist())\n",
        "\n",
        "            left_bucket = np.zeros(max(labels) + 1)\n",
        "            right_bucket = np.zeros(max(labels) + 1)\n",
        "\n",
        "    elif heuristic_name == 'info_gain':\n",
        "        for i in range(data.shape[0] - 1):\n",
        "            split_value = (data[i][attr_index] + data[i+1][attr_index]) / 2\n",
        "            for j in range(data.shape[0]):\n",
        "                if data[j][attr_index] <= split_value:\n",
        "                    left_bucket[labels[j]] = left_bucket[labels[j]] + 1\n",
        "                else: \n",
        "                    right_bucket[labels[j]] = right_bucket[labels[j]] + 1\n",
        "\n",
        "            parent_bucket = []\n",
        "            for k in range(len(left_bucket)):\n",
        "                parent_bucket.append(left_bucket[k] + right_bucket[k])\n",
        "            split_value_of_heuristic[i][0] = split_value\n",
        "            split_value_of_heuristic[i][1] = info_gain(parent_bucket, left_bucket.tolist(), right_bucket.tolist())\n",
        "            \n",
        "            left_bucket = np.zeros(max(labels) + 1)\n",
        "            right_bucket = np.zeros(max(labels) + 1)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid Heuristic function\")\n",
        "\n",
        "    return split_value_of_heuristic"
      ],
      "metadata": {
        "id": "gmG0gqihxPQI"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chi_squared_test(left_bucket, right_bucket):\n",
        "    \"\"\"\n",
        "    Calculates chi squared value and degree of freedom between the selected attribute\n",
        "    and the class attribute. A bucket is a list of size num_classes. bucket[i] is the\n",
        "    number of examples that belong to class i.\n",
        "    :param left_bucket: Bucket belonging to the left child after the split.\n",
        "    :param right_bucket: Bucket belonging to the right child after the split.\n",
        "    :return: A float and and integer. Chi squared value and degree of freedom.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "        Chi squared value = (((Actual - Expected) ** 2) / Expected) \n",
        "        Degree of freedom =  (number of classes - 1) * (number of nodes - 1)\n",
        "        We calculate the Chi squared for the split as the sum of Chi squared for each node.\n",
        "        Higher the chi-square value more will be the purity of the nodes after a split.\n",
        "        Expected => worst case where the split didn't cause any kind of inclination towards purity. \n",
        "        In other words, the distribution of classes in the child node didn't change with respect to the parent class. \n",
        "    \"\"\"\n",
        "\n",
        "    parent_bucket = []\n",
        "    total_class_no = 0\n",
        "\n",
        "    for i in range(len(left_bucket)):\n",
        "        amount_of_instance = left_bucket[i] + right_bucket[i]\n",
        "        parent_bucket.append(amount_of_instance)\n",
        "        if amount_of_instance != 0:\n",
        "            total_class_no += 1\n",
        "\n",
        "\n",
        "    # number of nodes is 2 because we have only left and right child (it is binary)\n",
        "    # len(left_bucket) gives the number of classes\n",
        "    degree_of_freedom = (total_class_no - 1) * (2 - 1) \n",
        "\n",
        "\n",
        "    # calculation of chi square\n",
        "    chi_squared_value = 0\n",
        "    for i in range(len(left_bucket)):\n",
        "        if parent_bucket[i] != 0:\n",
        "            chi_squared_value += (((left_bucket[i] - ((parent_bucket[i] / sum(parent_bucket)) * sum(left_bucket))) ** 2) / ((parent_bucket[i] / sum(parent_bucket)) * sum(left_bucket))) \n",
        "            chi_squared_value += (((right_bucket[i] - ((parent_bucket[i] / sum(parent_bucket)) * sum(right_bucket))) ** 2) / ((parent_bucket[i] / sum(parent_bucket)) * sum(right_bucket))) \n",
        "\n",
        "    return chi_squared_value, degree_of_freedom"
      ],
      "metadata": {
        "id": "Wc02fH1hxXhg"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_bucket = [3, 2, 3]\n",
        "left_bucket = [3, 0, 2]\n",
        "right_bucket = [0, 2, 1]\n",
        "\n",
        "print('entropy:', abs(entropy(parent_bucket) - 1.5612781244591325) < 10 ** -5)\n",
        "\n",
        "print('info_gain:', abs(info_gain(parent_bucket, left_bucket, right_bucket) - 0.610073065154531) < 10 ** -5)\n",
        "\n",
        "print('gini:', abs(gini(parent_bucket) - 0.65625) < 10 ** -5)\n",
        "\n",
        "print('avg_gini_index:', abs(avg_gini_index(left_bucket, right_bucket) - 0.4666666666666667) < 10 ** -5)\n",
        "\n",
        "data = np.asarray([\n",
        "    [0.96712763, 0.27892349, 0.69429896, 0.04024055],\n",
        "    [0.0576444, 0.33726678, 0.57879485, 0.81960005],\n",
        "    [0.70768221, 0.30983012, 0.80722421, 0.13924751],\n",
        "    [0.42084337, 0.7296714, 0.00308904, 0.24135345],\n",
        "    [0.65534721, 0.44364458, 0.63468942, 0.27418721],\n",
        "    [0.98472834, 0.6466202, 0.18471949, 0.9535479],\n",
        "    [0.63624549, 0.30568322, 0.41870169, 0.85743963],\n",
        "    [0.17610217, 0.20381821, 0.68492418, 0.57177705],\n",
        "    [0.21855323, 0.97823166, 0.38690695, 0.79345037],\n",
        "    [0.53118909, 0.74468352, 0.88166667, 0.50417511]\n",
        "])\n",
        "\n",
        "values_info_gain_gt = np.asarray([\n",
        "    [0.24137085, 0.07898214],\n",
        "    [0.29230335, 0.17095059],\n",
        "    [0.30775667, 0.2812909],\n",
        "    [0.32354845, 0.41997309],\n",
        "    [0.39045568, 0.12451125],\n",
        "    [0.54513239, 0.25642589],\n",
        "    [0.6881458, 0.09127745],\n",
        "    [0.73717746, 0.00740339],\n",
        "    [0.86145759, 0.07898214]\n",
        "])\n",
        "\n",
        "values_avg_gini_index_gt = np.asarray([\n",
        "    [0.24137085, 0.44444444],\n",
        "    [0.29230335, 0.4],\n",
        "    [0.30775667, 0.34285714],\n",
        "    [0.32354845, 0.26666667],\n",
        "    [0.39045568, 0.4],\n",
        "    [0.54513239, 0.31666667],\n",
        "    [0.6881458, 0.41904762],\n",
        "    [0.73717746, 0.475],\n",
        "    [0.86145759, 0.44444444]\n",
        "])\n",
        "\n",
        "labels = np.asarray([0, 1, 0, 1, 0, 1, 0, 0, 0, 1])\n",
        "\n",
        "\n",
        "values_info_gain = calculate_split_values(data, labels, 2, 1, 'info_gain')\n",
        "\n",
        "values_avg_gini_index = calculate_split_values(data, labels, 2, 1, 'avg_gini_index')\n",
        "\n",
        "print('calculate_split_values (info_gain): ', np.all(np.abs(values_info_gain - values_info_gain_gt) < 10 ** -5))\n",
        "print('calculate_split_values (avg_gini_index): ',\n",
        "      np.all(np.abs(values_avg_gini_index - values_avg_gini_index_gt) < 10 ** -5))\n",
        "\n",
        "\n",
        "chi_squared, df = chi_squared_test(left_bucket, right_bucket)\n",
        "print('chi_squared:', abs(chi_squared - 5.155555555555557) < 10 ** -5)\n",
        "print('degree_of_freedom:', df == 2)\n",
        "\n",
        "left_bucket2 = [0 , 3, 2]\n",
        "right_bucket2 = [0, 1, 4]\n",
        "chi_squared2, df2 = chi_squared_test(left_bucket2, right_bucket2)\n",
        "print('chi_squared:', abs(chi_squared2 - 1.6666666666666665) < 10 ** -5)\n",
        "print('degree_of_freedom:', df2 == 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrqHgLPUxXrs",
        "outputId": "5f6d4ca2-f2bc-4edf-d738-a0f59cce98c1"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entropy: True\n",
            "info_gain: True\n",
            "gini: True\n",
            "avg_gini_index: True\n",
            "calculate_split_values (info_gain):  True\n",
            "calculate_split_values (avg_gini_index):  True\n",
            "chi_squared: True\n",
            "degree_of_freedom: True\n",
            "chi_squared: True\n",
            "degree_of_freedom: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ID3 Algorithm:\n",
        "# Is top-down meaning that it starts building the tree from the top\n",
        "# and it is greedy meaning that at each iteration we select the best\n",
        "# feature at the present moment to create a node\n",
        "\n",
        "print(train_set.shape)\n",
        "print(train_labels)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C_pwK0ICNy8",
        "outputId": "41371fb3-5e04-4c76-c876-5e83f4f7c859"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "[0 0 0 1 2 1 0 1 0 1 2 0 2 2 0 1 0 2 2 1 0 0 0 1 0 2 0 1 1 0 0 1 1 0 1 0 2\n",
            " 1 2 1 2 0 0 1 2 2 0 0 0 1 0 0 2 2 1 2 2 0 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 2\n",
            " 2 0 0 2 0 2 0 0 2 1 0 1 2 2 2 1 1 2 1 2 2 2 0 2 1 1 0 2 1 1 1 1 1 0 0 0 0\n",
            " 1 2 2 0 2 0 1 2 0]\n",
            "(120,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_buckets_and_subtrees(data, data_label, split_value, attr_index):\n",
        "    left_bucket = np.zeros(max(data_label) + 1)\n",
        "    right_bucket = np.zeros(max(data_label) + 1)\n",
        "    left_subtree = []\n",
        "    left_subtree_label = []\n",
        "    right_subtree = []\n",
        "    right_subtree_label = []\n",
        "    for i in range(data.shape[0]):\n",
        "        if data[i][attr_index] <= split_value:\n",
        "            left_bucket[data_label[i]] = left_bucket[data_label[i]] + 1\n",
        "            left_subtree.append(data[i])\n",
        "            left_subtree_label.append(data_label[i])\n",
        "        else: \n",
        "            right_bucket[data_label[i]] = right_bucket[data_label[i]] + 1\n",
        "            right_subtree.append(data[i])\n",
        "            right_subtree_label.append(data_label[i])\n",
        "\n",
        "    left_tree = np.zeros((len(left_subtree), data.shape[1]))\n",
        "    for i in range(len(left_subtree)):\n",
        "        left_tree[i] = left_subtree[i]\n",
        "\n",
        "    right_tree = np.zeros((len(right_subtree), data.shape[1]))\n",
        "    for i in range(len(right_subtree)):\n",
        "        right_tree[i] = right_subtree[i]\n",
        "\n",
        "    return left_bucket, right_bucket, left_tree, right_tree, left_subtree_label, right_subtree_label"
      ],
      "metadata": {
        "id": "rqoQKJ-GRjfn"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tree:\n",
        "    def __init__(self, classes, separating_feature, splitting_value):\n",
        "        self.separating_feature = separating_feature\n",
        "        self.splitting_value = splitting_value\n",
        "        self.children = []\n",
        "        self.classes = classes"
      ],
      "metadata": {
        "id": "Q8sGxZQiHD7B"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_parent_bucket(left_bucket, right_bucket):\n",
        "    parent_bucket = []\n",
        "    for i in range(max(len(left_bucket), len(right_bucket))):\n",
        "        if (i <= (len(left_bucket) - 1)) & (i <= (len(right_bucket) - 1)):\n",
        "            parent_bucket.append(left_bucket[i] + right_bucket[i])\n",
        "        elif (i > (len(left_bucket) - 1)) & (i <= (len(right_bucket) - 1)):\n",
        "            parent_bucket.append(right_bucket[i])\n",
        "        else:\n",
        "            parent_bucket.append(left_bucket[i])\n",
        "    \n",
        "    return parent_bucket"
      ],
      "metadata": {
        "id": "QqQYRTKzICfR"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is for visualization\n",
        "def print_tree(root):\n",
        "  thislevel = [root]\n",
        "\n",
        "  while thislevel:\n",
        "    nextlevel = []\n",
        "    for n in thislevel:\n",
        "      print(\"classes: \", n.classes, \"   separating feature index: \", n.separating_feature, \"   splitting value: \", n.splitting_value, end=' ')\n",
        "      if n.children[0] is not None: \n",
        "          nextlevel.append(n.children[0])\n",
        "          nextlevel.append(n.children[1])\n",
        "          print(\" children[0] = \", n.children[0].classes, \"   children[1] = \", n.children[1].classes)\n",
        "      else:\n",
        "          print(\" children = NULL\")\n",
        "\n",
        "    thislevel = nextlevel\n"
      ],
      "metadata": {
        "id": "tUP3DpqJTR-f"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ID3_algorithm(data, data_label, heuristic_function):\n",
        "    heuristic_of_attributes = np.zeros((train_set.shape[1], 2))\n",
        "    for attribute in range(data.shape[1]):\n",
        "        split_value_of_feature = calculate_split_values(data, data_label, 3, attribute, heuristic_function)\n",
        "        if heuristic_function == 'avg_gini_index':\n",
        "            max_info_gain_feature = np.amin(split_value_of_feature, axis=0)\n",
        "        else:\n",
        "            max_info_gain_feature = np.amax(split_value_of_feature, axis=0)\n",
        "        \n",
        "        result = np.nonzero(split_value_of_feature == max_info_gain_feature[1])\n",
        "        heuristic_of_attributes[attribute] = split_value_of_feature[result[0][0]]\n",
        "\n",
        "    # result[0][0] holds the index of the feature that has the maximum information gain\n",
        "    # heuristic_of_attributes[result[0][0]][0] holds the split value of the attribute that gives the most information \n",
        "    # and result[0][1] gives the value of information gain for that attribute\n",
        "    max_info_gain_feature = np.amax(heuristic_of_attributes, axis=0)\n",
        "    result = np.nonzero(heuristic_of_attributes == max_info_gain_feature[1])\n",
        "\n",
        "    left_bucket, right_bucket, left_subtree, right_subtree, left_subtree_label, right_subtree_label = find_buckets_and_subtrees(data, data_label, heuristic_of_attributes[result[0][0]][0], result[0][0])\n",
        "    chi, freedom = chi_squared_test(left_bucket, right_bucket)\n",
        "    # The degree of freedom is fixed for a given dataset\n",
        "    # In this homework, you will use 90% confidence.\n",
        "    # There are 3 classes and 2 subtrees. So the freedom is (3-1) * (2-1) = 2\n",
        "    # 0.211 = 21.1%\n",
        "    root = Tree(calculate_parent_bucket(left_bucket, right_bucket), result[0][0], heuristic_of_attributes[result[0][0]][0])\n",
        "    # You are going to stop growing the tree when there is no association between the attribute selected\n",
        "    # by the heuristic function, i.e., information gain and average gain index, and the class variable\n",
        "    if (chi / 100) > 0.211:\n",
        "        left = ID3_algorithm(left_subtree, left_subtree_label, heuristic_function)\n",
        "        right = ID3_algorithm(right_subtree, right_subtree_label, heuristic_function)\n",
        "        root.children = [left, right]\n",
        "\n",
        "    else:\n",
        "        root.children = [None, None]\n",
        "    \n",
        "    return root\n"
      ],
      "metadata": {
        "id": "sTHvOD13PCuL"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function is used to check if the node is pure or not. \n",
        "def check_purity_of_node(tree):\n",
        "    amount_of_empty_classes = 0\n",
        "    for i in range(len(tree.classes)):\n",
        "        if tree.classes[i] == 0:\n",
        "            amount_of_empty_classes += 1\n",
        "    \n",
        "    if (amount_of_empty_classes != len(tree.classes) - 1):\n",
        "        return False\n",
        "    else:\n",
        "        return True"
      ],
      "metadata": {
        "id": "TjZBEw0pw53b"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ID3_algorithm_without_prepruning(data, data_label, heuristic_function):\n",
        "    if len(data) > 1:\n",
        "        heuristic_of_attributes = np.zeros((train_set.shape[1], 2))\n",
        "        for attribute in range(data.shape[1]):\n",
        "            split_value_of_feature = calculate_split_values(data, data_label, 3, attribute, heuristic_function)\n",
        "            if heuristic_function == 'avg_gini_index':\n",
        "                max_info_gain_feature = np.amin(split_value_of_feature, axis=0)\n",
        "            else:\n",
        "                max_info_gain_feature = np.amax(split_value_of_feature, axis=0)\n",
        "            result = np.nonzero(split_value_of_feature == max_info_gain_feature[1])\n",
        "            heuristic_of_attributes[attribute] = split_value_of_feature[result[0][0]]\n",
        "\n",
        "        # result[0][0] holds the index of the feature that has the maximum information gain\n",
        "        # heuristic_of_attributes[result[0][0]][0] holds the split value of the attribute that gives the most information \n",
        "        # and result[0][1] gives the value of information gain for that attribute\n",
        "        max_info_gain_feature = np.amax(heuristic_of_attributes, axis=0)\n",
        "        result = np.nonzero(heuristic_of_attributes == max_info_gain_feature[1])\n",
        "\n",
        "        left_bucket, right_bucket, left_subtree, right_subtree, left_subtree_label, right_subtree_label = find_buckets_and_subtrees(data, data_label, heuristic_of_attributes[result[0][0]][0], result[0][0])\n",
        "    \n",
        "        # The degree of freedom is fixed for a given dataset\n",
        "        # In this homework, you will use 90% confidence.\n",
        "        # There are 3 classes and 2 subtrees. So the freedom is (3-1) * (2-1) = 2\n",
        "        # 0.211 = 21.1%\n",
        "        root = Tree(calculate_parent_bucket(left_bucket, right_bucket), result[0][0], heuristic_of_attributes[result[0][0]][0])\n",
        "        # we are going to stop growing a branch of the tree if its pure\n",
        "        if check_purity_of_node(root) == False:\n",
        "            left = ID3_algorithm_without_prepruning(left_subtree, left_subtree_label, heuristic_function)\n",
        "            right = ID3_algorithm_without_prepruning(right_subtree, right_subtree_label, heuristic_function)\n",
        "            root.children = [left, right]\n",
        "\n",
        "        else:\n",
        "            root.children = [None, None]\n",
        "    else:\n",
        "        root = Tree([], None, None)\n",
        "        root.children = [None, None]\n",
        "    return root\n"
      ],
      "metadata": {
        "id": "j8gTh9kUwWrJ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre Pruning\\n\\n\")\n",
        "root_based_on_info_gain = ID3_algorithm(train_set, train_labels, \"info_gain\")\n",
        "print(\"Visualization of Decision Tree based on Info gain with prepruning\")\n",
        "print_tree(root_based_on_info_gain)\n",
        "\n",
        "root_based_on_gini_index = ID3_algorithm(train_set, train_labels, \"avg_gini_index\")\n",
        "print(\"\\n\\nVisualization of Decision Tree based on Gini Index with prepruning\")\n",
        "print_tree(root_based_on_gini_index)\n",
        "\n",
        "print(\"\\n\\nWithout Pre Pruning\\n\")\n",
        "root_based_on_info_gain_without_prepruning = ID3_algorithm_without_prepruning(train_set, train_labels, \"info_gain\")\n",
        "print(\"\\nVisualization of Decision Tree based on Info gain without prepruning\")\n",
        "print_tree(root_based_on_info_gain_without_prepruning)\n",
        "\n",
        "root_based_on_gini_index_without_prepruning = ID3_algorithm_without_prepruning(train_set, train_labels, \"avg_gini_index\")\n",
        "print(\"\\n\\nVisualization of Decision Tree based on Gini Index without prepruning\")\n",
        "print_tree(root_based_on_gini_index_without_prepruning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Oz1qDyAS0yg",
        "outputId": "82539ec7-eb6e-45c4-8cba-fd1fe0d9efb1"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre Pruning\n",
            "\n",
            "\n",
            "Visualization of Decision Tree based on Info gain with prepruning\n",
            "classes:  [40.0, 43.0, 37.0]    separating feature index:  2    splitting value:  1.9  children[0] =  [40.0]    children[1] =  [0.0, 43.0, 37.0]\n",
            "classes:  [40.0]    separating feature index:  0    splitting value:  4.35  children = NULL\n",
            "classes:  [0.0, 43.0, 37.0]    separating feature index:  3    splitting value:  1.7  children[0] =  [0.0, 42.0, 4.0]    children[1] =  [0.0, 1.0, 33.0]\n",
            "classes:  [0.0, 42.0, 4.0]    separating feature index:  2    splitting value:  4.9  children = NULL\n",
            "classes:  [0.0, 1.0, 33.0]    separating feature index:  2    splitting value:  4.8  children = NULL\n",
            "\n",
            "\n",
            "Visualization of Decision Tree based on Gini Index with prepruning\n",
            "classes:  [40.0, 43.0, 37.0]    separating feature index:  1    splitting value:  3.3  children[0] =  [15.0, 42.0, 33.0]    children[1] =  [25.0, 1.0, 4.0]\n",
            "classes:  [15.0, 42.0, 33.0]    separating feature index:  1    splitting value:  2.9  children = NULL\n",
            "classes:  [25.0, 1.0, 4.0]    separating feature index:  1    splitting value:  3.4  children = NULL\n",
            "\n",
            "\n",
            "Without Pre Pruning\n",
            "\n",
            "\n",
            "Visualization of Decision Tree based on Info gain without prepruning\n",
            "classes:  [40.0, 43.0, 37.0]    separating feature index:  2    splitting value:  1.9  children[0] =  [40.0]    children[1] =  [0.0, 43.0, 37.0]\n",
            "classes:  [40.0]    separating feature index:  0    splitting value:  4.35  children = NULL\n",
            "classes:  [0.0, 43.0, 37.0]    separating feature index:  3    splitting value:  1.7  children[0] =  [0.0, 42.0, 4.0]    children[1] =  [0.0, 1.0, 33.0]\n",
            "classes:  [0.0, 42.0, 4.0]    separating feature index:  2    splitting value:  4.9  children[0] =  [0.0, 40.0, 1.0]    children[1] =  [0.0, 2.0, 3.0]\n",
            "classes:  [0.0, 1.0, 33.0]    separating feature index:  2    splitting value:  4.8  children[0] =  [0.0, 1.0, 1.0]    children[1] =  [0.0, 0.0, 32.0]\n",
            "classes:  [0.0, 40.0, 1.0]    separating feature index:  3    splitting value:  1.6  children[0] =  [0.0, 40.0]    children[1] =  []\n",
            "classes:  [0.0, 2.0, 3.0]    separating feature index:  1    splitting value:  2.6500000000000004  children[0] =  [0.0, 0.0, 2.0]    children[1] =  [0.0, 2.0, 1.0]\n",
            "classes:  [0.0, 1.0, 1.0]    separating feature index:  0    splitting value:  6.050000000000001  children[0] =  []    children[1] =  []\n",
            "classes:  [0.0, 0.0, 32.0]    separating feature index:  0    splitting value:  5.65  children = NULL\n",
            "classes:  [0.0, 40.0]    separating feature index:  0    splitting value:  4.95  children = NULL\n",
            "classes:  []    separating feature index:  None    splitting value:  None  children = NULL\n",
            "classes:  [0.0, 0.0, 2.0]    separating feature index:  0    splitting value:  6.05  children = NULL\n",
            "classes:  [0.0, 2.0, 1.0]    separating feature index:  0    splitting value:  6.95  children[0] =  [0.0, 2.0]    children[1] =  []\n",
            "classes:  []    separating feature index:  None    splitting value:  None  children = NULL\n",
            "classes:  []    separating feature index:  None    splitting value:  None  children = NULL\n",
            "classes:  [0.0, 2.0]    separating feature index:  0    splitting value:  6.35  children = NULL\n",
            "classes:  []    separating feature index:  None    splitting value:  None  children = NULL\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-f51f5f7debb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_based_on_info_gain_without_prepruning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mroot_based_on_gini_index_without_prepruning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg_gini_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nVisualization of Decision Tree based on Gini Index without prepruning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_based_on_gini_index_without_prepruning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# we are going to stop growing a branch of the tree if its pure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# we are going to stop growing a branch of the tree if its pure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# we are going to stop growing a branch of the tree if its pure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# we are going to stop growing a branch of the tree if its pure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "... last 1 frames repeated, from the frame below ...\n",
            "\u001b[0;32m<ipython-input-120-dbec2a4de0ee>\u001b[0m in \u001b[0;36mID3_algorithm_without_prepruning\u001b[0;34m(data, data_label, heuristic_function)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# we are going to stop growing a branch of the tree if its pure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_purity_of_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID3_algorithm_without_prepruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_subtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_subtree_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(tree, data):\n",
        "    while (tree.children[0] is not None):\n",
        "        if tree.splitting_value > data[tree.separating_feature]:\n",
        "            tree = tree.children[0]\n",
        "        else:\n",
        "            tree = tree.children[1]\n",
        "\n",
        "    max_value = max(tree.classes) \n",
        "    most_common_class = tree.classes.index(max_value) \n",
        "    return most_common_class"
      ],
      "metadata": {
        "id": "2q8T4ixCDHAM"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_accuracy(predictions, actual_label):\n",
        "    error = 0\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] != actual_label[i]:\n",
        "            error += 1\n",
        "\n",
        "    # return the accuracy\n",
        "    return (1 - (error / len(predictions)))"
      ],
      "metadata": {
        "id": "XIlSMOP0GRkw"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(len(test_labels)):\n",
        "    predictions.append(predict_label(root_based_on_info_gain, test_set[i]))\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "print(\"Accuracy based on info gain with preprunning = \", find_accuracy(predictions, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmECjWuNB5m6",
        "outputId": "cc63ab76-1861-4194-c228-a93172330203"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 2, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1, 2]\n",
            "Accuracy based on info gain with preprunning =  0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(len(test_labels)):\n",
        "    predictions.append(predict_label(root_based_on_gini_index, test_set[i]))\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "print(\"Accuracy based on gini index with preprunning = \", find_accuracy(predictions, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC2YBuwIGzJE",
        "outputId": "1da35993-6baa-46e5-fb82-e3897ac84c37"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "Accuracy based on gini index with preprunning =  0.43333333333333335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(len(test_labels)):\n",
        "    predictions.append(predict_label(root_based_on_info_gain_without_prepruning, test_set[i]))\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "print(\"Accuracy based on info gain without preprunning = \", find_accuracy(predictions, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH3uSS2uG_iV",
        "outputId": "1f6271d6-2827-4925-872b-0ba14c7e881f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 2, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 1, 0, 1, 2]\n",
            "Accuracy based on info gain without preprunning =  0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_based_on_gini_index = ID3_algorithm(train_set, train_labels, \"avg_gini_index\")\n",
        "print(\"\\n\\nVisualization of Decision Tree based on Gini Index with prepruning\")\n",
        "print_tree(root_based_on_gini_index)\n",
        "#root_based_on_gini_index = ID3_algorithm(train_set, train_labels, \"info_gain\")\n",
        "#print(\"\\n\\nVisualization of Decision Tree based on Gini Index with prepruning\")\n",
        "#print_tree(root_based_on_gini_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWJZYs63IiQk",
        "outputId": "077fdc56-7972-4e8a-984c-c806b0925f24"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Visualization of Decision Tree based on Gini Index with prepruning\n",
            "classes:  [40.0, 43.0, 37.0]    separating feature index:  1    splitting value:  3.3  children[0] =  [15.0, 42.0, 33.0]    children[1] =  [25.0, 1.0, 4.0]\n",
            "classes:  [15.0, 42.0, 33.0]    separating feature index:  1    splitting value:  2.9  children = NULL\n",
            "classes:  [25.0, 1.0, 4.0]    separating feature index:  1    splitting value:  3.4  children = NULL\n"
          ]
        }
      ]
    }
  ]
}